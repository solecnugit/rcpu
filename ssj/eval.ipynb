{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import random \n",
    "import os\n",
    "import ujson\n",
    "\n",
    "from typing import List, Dict, Tuple, Union, Any\n",
    "\n",
    "def set_seed():\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icx_df = pd.read_parquet(\"out/icx.parquet\")\n",
    "clx_df = pd.read_parquet(\"out/clx.parquet\")\n",
    "\n",
    "icx_ssj = ujson.load(open(\"out/ssj.icx.json\"))\n",
    "clx_ssj = ujson.load(open(\"out/ssj.clx.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_df(df: pd.DataFrame):\n",
    "    df = df[\n",
    "        [\n",
    "            \"timestamp\",\n",
    "            \"%cpu_lc0\",\n",
    "            \"%cpu_lc1\",\n",
    "            \"cpu_lc0\",\n",
    "            \"cpu_lc1\",\n",
    "            \"phy_cpu\",\n",
    "            \"name\",\n",
    "            \"%cpu_phy\",\n",
    "        ]\n",
    "    ]\n",
    "    df_lc0 = df[[\"timestamp\", \"%cpu_lc0\", \"cpu_lc0\", \"phy_cpu\", \"%cpu_phy\", \"name\"]]\n",
    "    df_lc1 = df[[\"timestamp\", \"%cpu_lc1\", \"cpu_lc1\", \"phy_cpu\", \"%cpu_phy\", \"name\"]]\n",
    "\n",
    "    df_lc1 = df_lc1.rename(columns={\"%cpu_lc1\": \"%cpu_lc0\", \"cpu_lc1\": \"cpu_lc0\"})\n",
    "\n",
    "    df = pd.concat([df_lc0, df_lc1])\n",
    "    df = df.sort_values(by=[\"timestamp\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"%cpu_lc0\": \"%cpu\",\n",
    "            \"cpu_lc0\": \"cpu\",\n",
    "            \"phy_cpu\": \"phy\",\n",
    "            \"%cpu_phy\": \"%cpu_phy\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    cpu_df = df.pivot(index=[\"name\", \"timestamp\"], columns=\"cpu\", values=\"%cpu\")\n",
    "\n",
    "    phy_df = (\n",
    "        df.groupby([\"name\", \"timestamp\"])\n",
    "        .agg({\"%cpu_phy\": \"mean\"})\n",
    "        .rename(columns={\"%cpu_phy\": \"physical\"})\n",
    "    )\n",
    "\n",
    "    df = cpu_df.join(phy_df, on=[\"name\", \"timestamp\"], how=\"inner\")\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot data into row format\n",
    "icx_df = pivot_df(icx_df)\n",
    "clx_df = pivot_df(clx_df)\n",
    "\n",
    "# calculate remaining utilization\n",
    "icx_df[\"baseline\"] = icx_df.drop(columns=[\"name\", \"timestamp\", \"physical\"]).mean(axis=1)\n",
    "icx_df[\"remaining(baseline)\"] = 100 - icx_df[\"baseline\"]\n",
    "\n",
    "clx_df[\"baseline\"] = clx_df.drop(columns=[\"name\", \"timestamp\", \"physical\"]).mean(axis=1)\n",
    "clx_df[\"remaining(baseline)\"] = 100 - clx_df[\"baseline\"]\n",
    "\n",
    "cols = []\n",
    "tdf = icx_df.drop(\n",
    "    columns=[\"name\", \"timestamp\", \"physical\", \"baseline\", \"remaining(baseline)\"]\n",
    ")\n",
    "\n",
    "for a, b in tdf.columns.groupby(tdf.columns % 32).values():\n",
    "    tdf[f\"p{a}\"] = tdf[[a, b]].max(axis=1)\n",
    "    cols.append(f\"p{a}\")\n",
    "\n",
    "icx_df[\"adjusted\"] = tdf[cols].mean(axis=1)\n",
    "icx_df[\"remaining(rcpu)\"] = 100 - icx_df[\"adjusted\"]\n",
    "\n",
    "cols = []\n",
    "tdf = clx_df.drop(\n",
    "    columns=[\"name\", \"timestamp\", \"physical\", \"baseline\", \"remaining(baseline)\"]\n",
    ")\n",
    "\n",
    "for a, b in tdf.columns.groupby(tdf.columns % 40).values():\n",
    "    tdf[f\"p{a}\"] = tdf[[a, b]].max(axis=1)\n",
    "    cols.append(f\"p{a}\")\n",
    "\n",
    "clx_df[\"adjusted\"] = tdf[cols].mean(axis=1)\n",
    "\n",
    "clx_df[\"remaining(rcpu)\"] = 100 - clx_df[\"adjusted\"]\n",
    "\n",
    "icx_df[\"remaining(physical)\"] = 100 - icx_df[\"physical\"]\n",
    "clx_df[\"remaining(physical)\"] = 100 - clx_df[\"physical\"]\n",
    "\n",
    "icx_df = icx_df.reset_index(drop=True)\n",
    "clx_df = clx_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset\n",
    "\n",
    "cols_to_drop_when_x = [\n",
    "    \"name\",\n",
    "    \"timestamp\",\n",
    "    \"physical\",\n",
    "    \"baseline\",\n",
    "    \"adjusted\",\n",
    "    \"remaining(baseline)\",\n",
    "    \"remaining(rcpu)\",\n",
    "    \"remaining(physical)\",\n",
    "]\n",
    "\n",
    "ICX_X = icx_df.drop(columns=cols_to_drop_when_x)\n",
    "CLX_X = clx_df.drop(columns=cols_to_drop_when_x)\n",
    "\n",
    "# padding features to 40\n",
    "ICX_X.columns = [i for i in range(32)]\n",
    "for i in range(32, 40):\n",
    "    ICX_X[i] = 0\n",
    "\n",
    "CLX_X.columns = [i for i in range(40)]\n",
    "\n",
    "ICX_y = icx_df[\"remaining(physical)\"]\n",
    "CLX_y = clx_df[\"remaining(physical)\"]\n",
    "\n",
    "icx_X_train, icx_X_test, icx_y_train, icx_y_test = train_test_split(\n",
    "    ICX_X, ICX_y, test_size=0.2, random_state=42\n",
    ")\n",
    "clx_X_train, clx_X_test, clx_y_train, clx_y_test = train_test_split(\n",
    "    CLX_X, CLX_y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import time\n",
    "\n",
    "GLOBAL_ERRORS = []\n",
    "GLOBAL_SPEED = []\n",
    "\n",
    "RANDOM_INPUT_ARRAY = np.random.random((10000, 40)) * 100 # for speed test\n",
    "\n",
    "# Evaluation functions\n",
    "# NOTE: The utilization data in our dataset is already normalized to 100.\n",
    "#       Thus, the error mentioned in our evaluation is in percentage.\n",
    "#       We report the raw value in our paper\n",
    "def eval_on_icx(model, train_on):\n",
    "    model_name = model.__class__.__name__\n",
    "    eval_on = \"ICX\"\n",
    "\n",
    "    y_pred = model.predict(icx_X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(icx_y_test, y_pred))\n",
    "    mae = mean_absolute_error(icx_y_test, y_pred)\n",
    "\n",
    "    GLOBAL_ERRORS.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"train\": train_on,\n",
    "            \"eval\": eval_on,\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def eval_on_clx(model, train_on):\n",
    "    model_name = model.__class__.__name__\n",
    "    eval_on = \"CLX\"\n",
    "\n",
    "    y_pred = model.predict(clx_X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(clx_y_test, y_pred))\n",
    "    mae = mean_absolute_error(clx_y_test, y_pred)\n",
    "\n",
    "    GLOBAL_ERRORS.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"train\": train_on,\n",
    "            \"eval\": eval_on,\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def eval_speed(model):\n",
    "    model_name = model.__class__.__name__\n",
    "    times = []\n",
    "\n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        model.predict(RANDOM_INPUT_ARRAY)\n",
    "\n",
    "    for _ in range(20):\n",
    "        start = time.clock_gettime_ns(time.CLOCK_MONOTONIC)\n",
    "        model.predict(RANDOM_INPUT_ARRAY) # Shape: (10000, 40)\n",
    "        end = time.clock_gettime_ns(time.CLOCK_MONOTONIC)\n",
    "\n",
    "        times.append(end - start)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    GLOBAL_SPEED.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"time\": np.mean(times),\n",
    "            \"times\": times,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import STATUS_OK, hp, tpe, Trials, fmin\n",
    "\n",
    "\n",
    "def icx_objective(space):\n",
    "    reg = create_model(space) # see function definition below\n",
    "\n",
    "    score = cross_val_score(\n",
    "        reg,\n",
    "        icx_X_train,\n",
    "        icx_y_train,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "    ).mean()\n",
    "\n",
    "    return {\"loss\": -score, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "def clx_objective(space):\n",
    "    reg = create_model(space)\n",
    "\n",
    "    score = cross_val_score(\n",
    "        reg,\n",
    "        clx_X_train,\n",
    "        clx_y_train,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "    ).mean()\n",
    "\n",
    "    return {\"loss\": -score, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "EVAL_TURNS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "\n",
    "def create_model(space):\n",
    "    return xgb.XGBRegressor(\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "        n_estimators=int(space[\"n_estimators\"]),\n",
    "        max_depth=int(space[\"max_depth\"]),\n",
    "        gamma=space[\"gamma\"],\n",
    "        reg_alpha=int(space[\"reg_alpha\"]),\n",
    "        min_child_weight=space[\"min_child_weight\"],\n",
    "        colsample_bytree=space[\"colsample_bytree\"],\n",
    "    )\n",
    "\n",
    "\n",
    "space = {\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 1, 9),\n",
    "    \"reg_alpha\": hp.quniform(\"reg_alpha\", 40, 180, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 1),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"min_child_weight\": hp.quniform(\"min_child_weight\", 0, 10, 1),\n",
    "    \"n_estimators\": hp.uniform(\"n_estimators\", 100, 1000),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "icx_best_params = fmin(\n",
    "    icx_objective, space, algo=tpe.suggest, max_evals=EVAL_TURNS, trials=trials\n",
    ")\n",
    "\n",
    "trials = Trials()\n",
    "clx_best_params = fmin(\n",
    "    clx_objective, space, algo=tpe.suggest, max_evals=EVAL_TURNS, trials=trials\n",
    ")\n",
    "\n",
    "icx_model = create_model(icx_best_params)\n",
    "clx_model = create_model(clx_best_params)\n",
    "\n",
    "icx_model.fit(icx_X_train, icx_y_train)\n",
    "clx_model.fit(clx_X_train, clx_y_train)\n",
    "\n",
    "eval_on_icx(icx_model, \"ICX\")\n",
    "eval_on_clx(clx_model, \"CLX\")\n",
    "\n",
    "eval_speed(icx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "set_seed()\n",
    "\n",
    "\n",
    "def create_model(space):\n",
    "    return KNeighborsRegressor(\n",
    "        n_neighbors=int(space[\"n_neighbors\"]),\n",
    "        #    weights=space[\"weights\"],\n",
    "        #    algorithm=space[\"algorithm\"],\n",
    "        leaf_size=int(space[\"leaf_size\"]),\n",
    "        p=int(space[\"p\"]),\n",
    "    )\n",
    "\n",
    "\n",
    "space = {\n",
    "    \"n_neighbors\": hp.uniform(\"n_neighbors\", 1, 100),\n",
    "    # \"weights\": hp.choice(\"weights\", [\"uniform\", \"distance\"]),\n",
    "    # \"algorithm\": hp.choice(\"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]),\n",
    "    \"leaf_size\": hp.uniform(\"leaf_size\", 1, 100),\n",
    "    \"p\": hp.uniform(\"p\", 1, 10),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "icx_best_params = fmin(\n",
    "    icx_objective, space, algo=tpe.suggest, max_evals=EVAL_TURNS, trials=trials\n",
    ")\n",
    "\n",
    "trials = Trials()\n",
    "clx_best_params = fmin(\n",
    "    clx_objective, space, algo=tpe.suggest, max_evals=EVAL_TURNS, trials=trials\n",
    ")\n",
    "\n",
    "icx_model = create_model(icx_best_params)\n",
    "clx_model = create_model(clx_best_params)\n",
    "\n",
    "icx_model.fit(icx_X_train, icx_y_train)\n",
    "clx_model.fit(clx_X_train, clx_y_train)\n",
    "\n",
    "eval_on_icx(icx_model, \"ICX\")\n",
    "eval_on_clx(clx_model, \"CLX\")\n",
    "\n",
    "eval_speed(icx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "set_seed()\n",
    "\n",
    "\n",
    "def create_model(space):\n",
    "    return LassoCV(\n",
    "        cv=int(space[\"cv\"]),\n",
    "        n_alphas=int(space[\"n_alphas\"]),\n",
    "        tol=space[\"tol\"],\n",
    "        max_iter=10000,\n",
    "    )\n",
    "\n",
    "\n",
    "space = {\n",
    "    \"cv\": hp.uniform(\"cv\", 2, 10),\n",
    "    \"n_alphas\": hp.uniform(\"n_alphas\", 1, 100),\n",
    "    \"tol\": hp.uniform(\"tol\", 0.0001, 0.001),\n",
    "    # \"max_iter\": hp.uniform(\"max_iter\", 100, 3000),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "icx_best_params = fmin(\n",
    "    icx_objective, space, algo=tpe.suggest, max_evals=EVAL_TURNS, trials=trials\n",
    ")\n",
    "\n",
    "trials = Trials()\n",
    "clx_best_params = fmin(\n",
    "    clx_objective, space, algo=tpe.suggest, max_evals=EVAL_TURNS, trials=trials\n",
    ")\n",
    "\n",
    "icx_model = create_model(icx_best_params)\n",
    "clx_model = create_model(clx_best_params)\n",
    "\n",
    "icx_model.fit(icx_X_train, icx_y_train)\n",
    "clx_model.fit(clx_X_train, clx_y_train)\n",
    "\n",
    "eval_on_icx(icx_model, \"ICX\")\n",
    "\n",
    "eval_on_clx(clx_model, \"CLX\")\n",
    "\n",
    "eval_speed(icx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "set_seed()\n",
    "\n",
    "\n",
    "def create_model(space):\n",
    "    return SVR(\n",
    "        # kernel=space[\"kernel\"],\n",
    "        degree=int(space[\"degree\"]),\n",
    "        gamma=space[\"gamma\"],\n",
    "        tol=space[\"tol\"],\n",
    "        C=space[\"C\"],\n",
    "        epsilon=space[\"epsilon\"],\n",
    "    )\n",
    "\n",
    "\n",
    "space = {\n",
    "    # \"kernel\": hp.choice(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "    \"degree\": hp.uniform(\"degree\", 1, 10),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 0.0001, 1),\n",
    "    \"tol\": hp.uniform(\"tol\", 0.0001, 0.001),\n",
    "    \"C\": hp.uniform(\"C\", 0.1, 100),\n",
    "    \"epsilon\": hp.uniform(\"epsilon\", 0.0001, 0.1),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "icx_best_params = fmin(\n",
    "    icx_objective, space, algo=tpe.suggest, max_evals=30, trials=trials\n",
    ")\n",
    "\n",
    "trials = Trials()\n",
    "clx_best_params = fmin(\n",
    "    clx_objective, space, algo=tpe.suggest, max_evals=30, trials=trials\n",
    ")\n",
    "\n",
    "icx_model = create_model(icx_best_params)\n",
    "clx_model = create_model(clx_best_params)\n",
    "\n",
    "icx_model.fit(icx_X_train, icx_y_train)\n",
    "clx_model.fit(clx_X_train, clx_y_train)\n",
    "\n",
    "eval_on_icx(icx_model, \"ICX\")\n",
    "eval_on_clx(clx_model, \"CLX\")\n",
    "\n",
    "eval_speed(icx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "set_seed()\n",
    "\n",
    "\n",
    "def create_model(space):\n",
    "    return MLPRegressor(\n",
    "        hidden_layer_sizes=(\n",
    "            int(space[\"hidden_layer_sizes1\"]),\n",
    "            int(space[\"hidden_layer_sizes2\"]),\n",
    "        ),\n",
    "        learning_rate_init=space[\"learning_rate\"],\n",
    "        max_iter=10000,\n",
    "        alpha=space[\"alpha\"],\n",
    "        momentum=space[\"momentum\"],\n",
    "        beta_1=space[\"beta_1\"],\n",
    "        beta_2=space[\"beta_2\"],\n",
    "        epsilon=space[\"epsilon\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "\n",
    "space = {\n",
    "    \"hidden_layer_sizes1\": hp.uniform(\"hidden_layer_sizes1\", 32, 128),\n",
    "    \"hidden_layer_sizes2\": hp.uniform(\"hidden_layer_sizes2\", 32, 128),\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.0001, 0.1),\n",
    "    # \"max_iter\": hp.uniform(\"max_iter\", 100, 1000),\n",
    "    \"alpha\": hp.uniform(\"alpha\", 0.0001, 0.1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.0001, 0.1),\n",
    "    \"beta_1\": hp.uniform(\"beta_1\", 0.0001, 0.1),\n",
    "    \"beta_2\": hp.uniform(\"beta_2\", 0.0001, 0.1),\n",
    "    \"epsilon\": hp.uniform(\"epsilon\", 0.0001, 0.1),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "icx_best_params = fmin(\n",
    "    icx_objective, space, algo=tpe.suggest, max_evals=30, trials=trials\n",
    ")\n",
    "\n",
    "trials = Trials()\n",
    "clx_best_params = fmin(\n",
    "    clx_objective, space, algo=tpe.suggest, max_evals=30, trials=trials\n",
    ")\n",
    "\n",
    "icx_model = create_model(icx_best_params)\n",
    "clx_model = create_model(clx_best_params)\n",
    "\n",
    "icx_model.fit(icx_X_train, icx_y_train)\n",
    "clx_model.fit(clx_X_train, clx_y_train)\n",
    "\n",
    "eval_on_icx(icx_model, \"ICX\")\n",
    "eval_on_clx(clx_model, \"CLX\")\n",
    "\n",
    "eval_speed(icx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval baseline\n",
    "\n",
    "y_pred = icx_df.iloc[icx_X_test.index][\"remaining(baseline)\"]\n",
    "\n",
    "rmse = mean_squared_error(icx_y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(icx_y_test, y_pred)\n",
    "\n",
    "GLOBAL_ERRORS.append(\n",
    "    {\n",
    "        \"model\": \"Baseline\",\n",
    "        \"train\": \"ICX\",\n",
    "        \"eval\": \"ICX\",\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "    }\n",
    ")\n",
    "\n",
    "y_pred = clx_df.iloc[clx_X_test.index][\"remaining(baseline)\"]\n",
    "\n",
    "rmse = mean_squared_error(clx_y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(clx_y_test, y_pred)\n",
    "\n",
    "GLOBAL_ERRORS.append(\n",
    "    {\n",
    "        \"model\": \"Baseline\",\n",
    "        \"train\": \"CLX\",\n",
    "        \"eval\": \"CLX\",\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "    }\n",
    ")\n",
    "\n",
    "# speed\n",
    "\n",
    "model_name = \"Baseline\"\n",
    "times = []\n",
    "\n",
    "for i in range(20):\n",
    "    start = time.clock_gettime_ns(time.CLOCK_MONOTONIC)\n",
    "    RANDOM_INPUT_ARRAY.mean(axis=1)\n",
    "    end = time.clock_gettime_ns(time.CLOCK_MONOTONIC)\n",
    "\n",
    "    times.append(end - start)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "GLOBAL_SPEED.append(\n",
    "    {\n",
    "        \"model\": model_name,\n",
    "        \"time\": np.mean(times),\n",
    "        \"times\": times,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval adjusted\n",
    "\n",
    "y_pred = icx_df.iloc[icx_X_test.index][\"remaining(rcpu)\"]\n",
    "\n",
    "rmse = mean_squared_error(icx_y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(icx_y_test, y_pred)\n",
    "\n",
    "GLOBAL_ERRORS.append(\n",
    "    {\n",
    "        \"model\": \"RCPU\",\n",
    "        \"train\": \"ICX\",\n",
    "        \"eval\": \"ICX\",\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "    }\n",
    ")\n",
    "\n",
    "y_pred = clx_df.iloc[clx_X_test.index][\"remaining(rcpu)\"]\n",
    "\n",
    "rmse = mean_squared_error(clx_y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(clx_y_test, y_pred)\n",
    "\n",
    "GLOBAL_ERRORS.append(\n",
    "    {\n",
    "        \"model\": \"RCPU\",\n",
    "        \"train\": \"CLX\",\n",
    "        \"eval\": \"CLX\",\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "    }\n",
    ")\n",
    "\n",
    "# speed\n",
    "model_name = \"RCPU\"\n",
    "times = []\n",
    "\n",
    "for i in range(20):\n",
    "    start = time.clock_gettime_ns(time.CLOCK_MONOTONIC)\n",
    "\n",
    "    # Take the maximum of every 2 hardware threads\n",
    "    # The topology follows Intel Ice Lake\n",
    "    # 0,20 is on the same physical core and 1,21 is on the same physical core ...\n",
    "    t = np.maximum(RANDOM_INPUT_ARRAY[:, :20], RANDOM_INPUT_ARRAY[:, 20:])\n",
    "    t = np.mean(t, axis=1)\n",
    "\n",
    "    end = time.clock_gettime_ns(time.CLOCK_MONOTONIC)\n",
    "\n",
    "    times.append(end - start)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "GLOBAL_SPEED.append(\n",
    "    {\n",
    "        \"model\": model_name,\n",
    "        \"time\": np.mean(times),\n",
    "        \"times\": times,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = pd.DataFrame.from_records(GLOBAL_ERRORS)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = pd.DataFrame.from_records(GLOBAL_SPEED)\n",
    "speed[\"speed\"] = speed[\"times\"].apply(np.mean)\n",
    "speed = speed[[\"model\", \"speed\"]]\n",
    "\n",
    "baseline = speed.loc[speed.model == \"Baseline\", \"speed\"].item()\n",
    "speed[\"relative\"] = speed[\"speed\"] / baseline\n",
    "speed = speed.sort_values(\"relative\")\n",
    "speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>eval</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>ICX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>23.253123</td>\n",
       "      <td>18.043626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>CLX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>22.209786</td>\n",
       "      <td>16.797020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjusted</td>\n",
       "      <td>ICX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>9.491374</td>\n",
       "      <td>5.591504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adjusted</td>\n",
       "      <td>CLX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>8.169406</td>\n",
       "      <td>4.658418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>ICX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>6.063179</td>\n",
       "      <td>3.631556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>ICX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>11.076135</td>\n",
       "      <td>6.738239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>CLX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>5.593573</td>\n",
       "      <td>2.933134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>CLX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>6.787734</td>\n",
       "      <td>4.180557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>ICX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>9.823221</td>\n",
       "      <td>7.720860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>ICX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>10.796655</td>\n",
       "      <td>8.021614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>CLX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>9.902777</td>\n",
       "      <td>7.614674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>CLX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>22.270653</td>\n",
       "      <td>19.223724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>ICX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>9.999983</td>\n",
       "      <td>8.533422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>ICX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>22.667880</td>\n",
       "      <td>20.439175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>CLX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>8.499703</td>\n",
       "      <td>7.164641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>CLX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>25.849335</td>\n",
       "      <td>15.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVR</td>\n",
       "      <td>ICX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>6.282390</td>\n",
       "      <td>3.789633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVR</td>\n",
       "      <td>ICX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>22.080112</td>\n",
       "      <td>18.882451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CLX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>5.615310</td>\n",
       "      <td>2.947600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CLX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>22.127780</td>\n",
       "      <td>19.137840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>ICX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>6.165396</td>\n",
       "      <td>3.695826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>ICX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>7.807649</td>\n",
       "      <td>4.680593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>CLX</td>\n",
       "      <td>CLX</td>\n",
       "      <td>5.734495</td>\n",
       "      <td>3.024050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>CLX</td>\n",
       "      <td>ICX</td>\n",
       "      <td>8.110557</td>\n",
       "      <td>5.842984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model train eval       rmse        mae\n",
       "0              Baseline   ICX  ICX  23.253123  18.043626\n",
       "1              Baseline   CLX  CLX  22.209786  16.797020\n",
       "2              Adjusted   ICX  ICX   9.491374   5.591504\n",
       "3              Adjusted   CLX  CLX   8.169406   4.658418\n",
       "8   KNeighborsRegressor   ICX  ICX   6.063179   3.631556\n",
       "9   KNeighborsRegressor   ICX  CLX  11.076135   6.738239\n",
       "10  KNeighborsRegressor   CLX  CLX   5.593573   2.933134\n",
       "11  KNeighborsRegressor   CLX  ICX   6.787734   4.180557\n",
       "12              LassoCV   ICX  ICX   9.823221   7.720860\n",
       "13              LassoCV   ICX  CLX  10.796655   8.021614\n",
       "14              LassoCV   CLX  CLX   9.902777   7.614674\n",
       "15              LassoCV   CLX  ICX  22.270653  19.223724\n",
       "20         MLPRegressor   ICX  ICX   9.999983   8.533422\n",
       "21         MLPRegressor   ICX  CLX  22.667880  20.439175\n",
       "22         MLPRegressor   CLX  CLX   8.499703   7.164641\n",
       "23         MLPRegressor   CLX  ICX  25.849335  15.179995\n",
       "16                  SVR   ICX  ICX   6.282390   3.789633\n",
       "17                  SVR   ICX  CLX  22.080112  18.882451\n",
       "18                  SVR   CLX  CLX   5.615310   2.947600\n",
       "19                  SVR   CLX  ICX  22.127780  19.137840\n",
       "4          XGBRegressor   ICX  ICX   6.165396   3.695826\n",
       "5          XGBRegressor   ICX  CLX   7.807649   4.680593\n",
       "6          XGBRegressor   CLX  CLX   5.734495   3.024050\n",
       "7          XGBRegressor   CLX  ICX   8.110557   5.842984"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = pd.read_parquet(\"./errors.parquet\")\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>speed</th>\n",
       "      <th>relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>1.094979e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adjusted</td>\n",
       "      <td>2.488465e+06</td>\n",
       "      <td>2.272615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>4.415395e+06</td>\n",
       "      <td>4.032403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>8.200339e+06</td>\n",
       "      <td>7.489039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>1.166389e+07</td>\n",
       "      <td>10.652162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>1.667209e+09</td>\n",
       "      <td>1522.594366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>2.159561e+09</td>\n",
       "      <td>1972.240036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model         speed     relative\n",
       "0             Baseline  1.094979e+06     1.000000\n",
       "1             Adjusted  2.488465e+06     2.272615\n",
       "4              LassoCV  4.415395e+06     4.032403\n",
       "6         MLPRegressor  8.200339e+06     7.489039\n",
       "2         XGBRegressor  1.166389e+07    10.652162\n",
       "3  KNeighborsRegressor  1.667209e+09  1522.594366\n",
       "5                  SVR  2.159561e+09  1972.240036"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed = pd.read_parquet(\"./speed.parquet\")\n",
    "speed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
